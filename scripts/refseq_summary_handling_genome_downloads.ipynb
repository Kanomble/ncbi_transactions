{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import wget\n",
    "import os\n",
    "import gzip\n",
    "from os.path import isfile\n",
    "import time\n",
    "import json\n",
    "#re.compile and re.findall\n",
    "import re\n",
    "#different package for downloading files from ncbi's ftp server\n",
    "import ftplib\n",
    "\n",
    "#ALL FUNCTIONS\n",
    "#summary_file_path = filepath to local assembly_summary_refseq.txt file --> STATIC FILE\n",
    "#refseq_level_checklist = list of assembly_levels e.g. ['Complete Genome'] --> USER INPUT\n",
    "def read_current_assembly_summary_with_pandas(summary_file_path, refseq_level_checklist):\n",
    "    #function for changing the ftp_header in the pandas table\n",
    "    def set_protein_assembly_file(ftp_path):\n",
    "        protein_genome = ftp_path.split('/')[-1:][0]\n",
    "        protein_genome = ftp_path + '/' + str(protein_genome) + '_protein.faa.gz'\n",
    "        return protein_genome\n",
    "\n",
    "    #init parsing refseq table with pandas\n",
    "    try:\n",
    "        #changed filepath input to full filepath (dependency)\n",
    "        #skip the first two rows as there are just some informations regarding the file\n",
    "        refseq_table = pd.read_table(summary_file_path, skiprows=[0, 1], header=None)\n",
    "        header = [\"assembly_accession\", \"bioproject\", \"biosample\", \"wgs_master\", \"refseq_category\", \"taxid\",\n",
    "                  \"species_taxid\", \"organism_name\", \"infraspecific_name\", \"isolate\", \"version_status\", \"assembly_level\",\n",
    "                  \"release_type\", \"genome_rep\", \"seq_rel_date\", \"asm_name\", \"submitter\", \"gbrs_paired_asm\",\n",
    "                  \"paired_asm_comp\", \"ftp_path\", \"excluded_from_refseq\", \"relation_to_type_material\"]\n",
    "        refseq_table.columns = header\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] Exception during pandas parsing of assembly_summary_refseq.txt file ...\\n\\tException: {}\".format(e))\n",
    "\n",
    "    #extract necessary data fields: assembly number, names, taxids and the correct ftp_filepath for downloading with gzip\n",
    "    try:\n",
    "        refseq_table = refseq_table[['assembly_accession', 'organism_name', 'taxid', 'species_taxid','assembly_level', 'ftp_path']]\n",
    "        refseq_table['ftp_path'] = refseq_table['ftp_path'].apply(lambda row: set_protein_assembly_file(row))\n",
    "        \n",
    "        #iterate over the refseq_level_checklist and append resulting dataframe to a list\n",
    "        pandas_genome_level_dataframes = []\n",
    "        for genome_level in refseq_level_checklist:\n",
    "            pandas_genome_level_dataframes.append(refseq_table[refseq_table['assembly_level'] == genome_level])\n",
    "            \n",
    "        #this generates a pandas dataframe with six columns ['assembly_accession', 'organism_name', 'taxid', 'species_taxid','assembly_level', 'ftp_path']\n",
    "        #and at most four different assembly_level entries\n",
    "        desired_refseq_genomes_dataframe = pd.concat(pandas_genome_level_dataframes)\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] Exception during filtering for assembly levels from refseq_table dataframe ...\\n\\tException: {}\".format(e))\n",
    "    return desired_refseq_genomes_dataframe\n",
    "\n",
    "#filter refseq table with taxids optained by the get_species_taxids.sh script\n",
    "def read_taxonomy_table(filepath):\n",
    "    if(isfile(filepath) == False):\n",
    "        raise Exception(\"[-] There is no taxonomy file called: {}\".format(filepath))\n",
    "    taxonomy_file = pd.read_table(filepath,header=None)\n",
    "    #species_taxid and taxid should normally be interchangeable, the species_taxid may inherit more informations\n",
    "    #to current strain (have a look at the README description of the refseq summary file)\n",
    "    taxonomy_file.columns = ['species_taxid']\n",
    "    return taxonomy_file\n",
    "\n",
    "def filter_table_by_taxonomy(refseq_table,taxonomy_table):\n",
    "    #species_taxid\n",
    "    return refseq_table.merge(taxonomy_table,how='inner', on=['species_taxid'])\n",
    "\n",
    "#returns the amount of filtered genomes\n",
    "def reduction_amount(refseq_table,filtered_table):\n",
    "    reduct = len(refseq_table) - len(filtered_table)\n",
    "    if(reduct <= 0):\n",
    "        raise Exception(\"[-] After filtering, there is no data remaining!\")\n",
    "    return reduct\n",
    "\n",
    "#downloading genomes with wget \n",
    "def download_genome_from_ftp_path(ftp_path):\n",
    "    try:\n",
    "        return wget.download(ftp_path)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "#function with two responsibilities in order to save memory usage\n",
    "def extract_downloaded_file_and_write_taxid_file(genome_downloaded_file,taxid):\n",
    "    \n",
    "    #decompression to fasta file\n",
    "    try:\n",
    "        output = open(genome_downloaded_file+\".decompressed.faa\",\"w\")\n",
    "        with gzip.open(genome_downloaded_file,\"rb\") as bytes_out:\n",
    "            bytes_from_file = bytes_out.read()\n",
    "            line = bytes_from_file.decode(\"utf-8\")\n",
    "            output.write(line)\n",
    "            output.close()\n",
    "        #remove gz file\n",
    "        os.remove(genome_downloaded_file)\n",
    "    except Exception as e:\n",
    "        output.close()\n",
    "        raise Exception(\"[-] Exception during decompressing: {}\".format(e))\n",
    "    \n",
    "    #creation of taxmap file | taxid \\t acc_id\n",
    "    try:\n",
    "        accession_id_pattern = re.compile('>(\\S*)')\n",
    "        taxmap = open('acc_taxid_map.table','a')\n",
    "        for acc_id in re.findall(accession_id_pattern,line):\n",
    "            taxmap.write(str(taxid)+\"\\t\"+str(acc_id)+\"\\n\")\n",
    "        taxmap.close()\n",
    "        #print(\"\\t[*] Done writing taxonomic informations into taxmap file ...\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        taxmap.close()\n",
    "        raise Exception(\"[-] Exception during writing taxmap file: {}\".format(e))\n",
    "        \n",
    "def download_assemblies(filtered_table):\n",
    "    try:\n",
    "        for genome_url,taxid in zip(filtered_table['ftp_path'],filtered_table['species_taxid']):\n",
    "            genome_file = download_genome_from_ftp_path(genome_url)\n",
    "            time.sleep(1)\n",
    "            #genome_file = wget.download(genome_url)\n",
    "            print(\"[+] downloaded genome: {}\\n[+] taxonomic node: {}\".format(genome_url,taxid))\n",
    "            if(genome_file):\n",
    "                extract_downloaded_file_and_write_taxid_file(genome_file,taxid)\n",
    "    except Exception as e:\n",
    "        print(\"[-] ERROR during download_assemblies\")\n",
    "        raise Exception(\"[-] Error during downloading assemblies with Exception: {}\".format(e))\n",
    "            \n",
    "def download_assemblies_with_ftplib(filtered_table):\n",
    "    def download_genome_assembly_ftplib(genome_url):\n",
    "        #genome_url = entry in filtered_table['ftp_path']\n",
    "        filename = genome_url.split('/')[-1]\n",
    "        directory = '/'+'/'.join(str(path) for path in genome_url.split('/')[3:-1])\n",
    "        try:\n",
    "            ftp.cwd(directory)\n",
    "            localfile = open(filename,'wb')\n",
    "            #print(\"[*] starting download\")\n",
    "            ftp.retrbinary('RETR '+filename,localfile.write,blocksize=1024)\n",
    "            localfile.close()\n",
    "            #print(\"[*] ended download\")\n",
    "            #return filename of the downloaded genome assembly, this is then used in extract_downloaded_file_and_write_taxid_file\n",
    "            return filename\n",
    "        except ftplib.error_perm as e:\n",
    "            #print(\"[-] ERROR DOWNLOADING\")\n",
    "            ftp.close()\n",
    "            raise Exception(\"[-] Error during downloading refseq file with Exception: {}\".format(e))\n",
    "            \n",
    "        \n",
    "    ftp = ftplib.FTP('ftp.ncbi.nlm.nih.gov')\n",
    "    ftp.login()\n",
    "    \n",
    "    for genome_url,taxid in zip(filtered_table['ftp_path'],filtered_table['species_taxid']):\n",
    "        genome_file = download_genome_assembly_ftplib(genome_url)\n",
    "        time.sleep(1)\n",
    "        #genome_downloaded_file = wget.download(genome_url)\n",
    "        print(\"[+] downloaded genome: {}\\n[+] taxonomic node: {}\".format(genome_url,taxid))\n",
    "        if(genome_file):\n",
    "            extract_downloaded_file_and_write_taxid_file(genome_file,taxid)\n",
    "            \n",
    "    ftp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run NCBI refseq genome assembly download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START]\n",
      "[*] reduced genome table to: 6\n",
      "[*] start to download assemblies ...\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_protein.faa.gz\n",
      "[+] taxonomic node: 9606\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/002/880/755/GCF_002880755.1_Clint_PTRv2/GCF_002880755.1_Clint_PTRv2_protein.faa.gz\n",
      "[+] taxonomic node: 9598\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/002/880/775/GCF_002880775.1_Susie_PABv2/GCF_002880775.1_Susie_PABv2_protein.faa.gz\n",
      "[+] taxonomic node: 9601\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/006/542/625/GCF_006542625.1_Asia_NLE_v1/GCF_006542625.1_Asia_NLE_v1_protein.faa.gz\n",
      "[+] taxonomic node: 61853\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/008/122/165/GCF_008122165.1_Kamilah_GGO_v0/GCF_008122165.1_Kamilah_GGO_v0_protein.faa.gz\n",
      "[+] taxonomic node: 9593\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/013/052/645/GCF_013052645.1_Mhudiblu_PPA_v0/GCF_013052645.1_Mhudiblu_PPA_v0_protein.faa.gz\n",
      "[+] taxonomic node: 9597\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_protein.faa.gz\n",
      "[+] taxonomic node: 9606\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/002/880/755/GCF_002880755.1_Clint_PTRv2/GCF_002880755.1_Clint_PTRv2_protein.faa.gz\n",
      "[+] taxonomic node: 9598\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/002/880/775/GCF_002880775.1_Susie_PABv2/GCF_002880775.1_Susie_PABv2_protein.faa.gz\n",
      "[+] taxonomic node: 9601\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/006/542/625/GCF_006542625.1_Asia_NLE_v1/GCF_006542625.1_Asia_NLE_v1_protein.faa.gz\n",
      "[+] taxonomic node: 61853\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/008/122/165/GCF_008122165.1_Kamilah_GGO_v0/GCF_008122165.1_Kamilah_GGO_v0_protein.faa.gz\n",
      "[+] taxonomic node: 9593\n",
      "[+] downloaded genome: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/013/052/645/GCF_013052645.1_Mhudiblu_PPA_v0/GCF_013052645.1_Mhudiblu_PPA_v0_protein.faa.gz\n",
      "[+] taxonomic node: 9597\n",
      "[+] this took 87 seconds\n",
      "[DONE]\n"
     ]
    }
   ],
   "source": [
    "if(isfile(\"../refseq_summary/assembly_summary_refseq.txt\")):\n",
    "    start = time.time()\n",
    "    print(\"[START]\")\n",
    "    refseq_table = read_current_assembly_summary_with_pandas('../refseq_summary/assembly_summary_refseq.txt',['Complete Genome','Chromosome'])\n",
    "    taxonomy_table = read_taxonomy_table('../taxonomic_nodes/apes.taxid')\n",
    "    filtered_table = filter_table_by_taxonomy(refseq_table,taxonomy_table)\n",
    "    print(\"[*] reduced genome table to: {}\".format(len(refseq_table)-reduction_amount(refseq_table,filtered_table)))\n",
    "    print(\"[*] start to download assemblies ...\")\n",
    "    download_assemblies_with_ftplib(filtered_table)\n",
    "    download_assemblies(filtered_table)\n",
    "    end = time.time()\n",
    "    print(\"[+] this took {} seconds\".format(round(end - start),2))\n",
    "    print(\"[DONE]\")\n",
    "else:\n",
    "    print(\"[ERROR]\")\n",
    "    print(\"\\t[-] There is no assembly_summary_refseq.txt file available!\")\n",
    "    print(\"[*] Downloading refseq summary file:\")\n",
    "    wget.download('ftp://ftp.ncbi.nih.gov/genomes/refseq/assembly_summary_refseq.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " 'Dockerfile',\n",
       " 'README.md',\n",
       " 'refseq_summary',\n",
       " 'requirements.txt',\n",
       " 'scripts',\n",
       " 'taxonomic_nodes']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping over pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "summary_dict={}\n",
    "accession = []\n",
    "organism_name = []\n",
    "for index, row in refseq_table[refseq_table['assembly_level'] == 'Complete Genome'].iterrows():\n",
    "    protein_genome = row['ftp_path'].split('/')[-1:][0]\n",
    "    protein_genome = row['ftp_path']+'/'+str(protein_genome)+'_protein.faa.gz'\n",
    "    accession.append(row['assembly_accession'])\n",
    "    organism_name.append(str(row['assembly_accession'])+\" \"+str(row['organism_name']))\n",
    "    summary_dict[row['assembly_accession']] = [protein_genome,row['taxid'],row['species_taxid'],row['organism_name']]\n",
    "html_input_list = tuple(zip(accession,organism_name))\n",
    "end = time.time()\n",
    "print(\"[+] function took {} seconds\".format(round(end - start),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas vectorized apply function\n",
    "\n",
    "Transforming refseq summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_protein_assembly_file(ftp_path):\n",
    "    protein_genome = ftp_path.split('/')[-1:][0]\n",
    "    protein_genome = ftp_path+'/'+str(protein_genome)+'_protein.faa.gz'\n",
    "    return protein_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#refseq_table = refseq_table[refseq_table['assembly_level'] == 'Complete Genome']\n",
    "refseq_table = refseq_table[['assembly_accession','organism_name','taxid','species_taxid','assembly_level','ftp_path']]\n",
    "refseq_table['ftp_path'] = refseq_table['ftp_path'].apply(lambda row:set_protein_assembly_file(row))\n",
    "end = time.time()\n",
    "print(\"[+] function took {} seconds\".format(round(end - start),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "refseq_table[refseq_table['assembly_level'] == 'Complete Genome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(refseq_table[refseq_table['assembly_level'] == 'Contig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_input_list = tuple(zip(refseq_table['assembly_accession'], refseq_table['organism_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summary_dict.keys()) == len(refseq_table['assembly_accession'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(refseq_table['assembly_accession'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that is used in the reciprocal BLAST software:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refseq_table_function_test = read_current_assembly_summary_with_pandas('./assembly_summary_refseq (1).txt',['Complete Genome','Chromosome'])\n",
    "refseq_table_function_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract desired genome level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refseq_level_checklist = list(refseq_table['assembly_level'].unique())\n",
    "pandas_genome_level_dataframes = []\n",
    "for genome_level in refseq_level_checklist:\n",
    "    pandas_genome_level_dataframes.append(refseq_table[refseq_table['assembly_level'] == genome_level])\n",
    "    \n",
    "desired_refseq_genomes_dataframe = pd.concat(pandas_genome_level_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(desired_refseq_genomes_dataframe['assembly_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "desired_refseq_genomes_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = desired_refseq_genomes_dataframe\n",
    "json_records = df.reset_index().to_json(orient ='records') \n",
    "data = [] \n",
    "data = json.loads(json_records) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_refseq_genomes_dataframe.head().to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(desired_refseq_genomes_dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download genome assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_url = refseq_table[refseq_table['assembly_level'] == \"Chromosome\"][0:2]['ftp_path'][1]\n",
    "taxid = refseq_table[refseq_table['assembly_level'] == \"Chromosome\"][0:2]['species_taxid'][1]\n",
    "genome_file = download_genome_from_ftp_path(genome_url)\n",
    "#genome_downloaded_file = wget.download(genome_url)\n",
    "print(\"[+] downloaded genome: {}\\n[+] taxonomic node: {}\".format(genome_url,taxid))\n",
    "\n",
    "if(genome_file):\n",
    "    extract_downloaded_file_and_write_taxid_file(genome_file,taxid)\n",
    "#genome_downloaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(genome_downloaded_file+\".decompressed.faa\",\"w\")\n",
    "with gzip.open(genome_downloaded_file,\"rb\") as bytes_out:\n",
    "    bytes_from_file = bytes_out.read()\n",
    "    line = bytes_from_file.decode(\"utf-8\")\n",
    "    output.write(line)\n",
    "    output.close()\n",
    "\n",
    "print(\"[*] bytes length: {} type: {}\".format(len(bytes_from_file),type(bytes_from_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accession_id_pattern = re.compile('>(\\S*)')\n",
    "taxmap = open('acc_taxid_map.table','w')\n",
    "for acc_id in re.findall(accession_id_pattern,line):\n",
    "    taxmap.write(str(taxid)+\"\\t\"+str(acc_id)+\"\\n\")\n",
    "taxmap.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_file = genome_downloaded_file+'.decompressed.faa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.remove(genome_downloaded_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regex for accession id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "accession_id_pattern = re.compile('^>(\\S*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = re.match(regex,'>test hello')\n",
    "res.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(re.match(regex,'>test hello')):\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = re.match(regex,'test hello')\n",
    "res == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read process information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] Exception occured: [WinError 193] %1 ist keine zulÃ¤ssige Win32-Anwendung\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    pid = subprocess.Popen(['get_species_taxids.sh','-t','Eubacteria','>','eubacteria.taxid'])\n",
    "    #print(pid.pid)\n",
    "    #pid.communicate()\n",
    "    #outs, errs = pid.communicate(timeout=2)\n",
    "    print(\"[+] spawned new process: {}\".format(pid.pid))\n",
    "    #print(\"[+] errs : {}\".format(errs))\n",
    "except Exception as e:\n",
    "    print(\"[-] Exception occured: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-b20ad7c2e1f3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mpid\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpoll\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'pid' is not defined"
     ]
    }
   ],
   "source": [
    "pid.poll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid.returncode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# limit by taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refseq_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_file = pd.read_table('apes.taxid',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_file.columns = ['species_taxid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_table = refseq_table.merge(taxonomy_file,how='inner', on=['species_taxid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[+] filtered the original refseq table with {} entries against {} taxonomic nodes ...\\n\\t {} entries remain\".format(len(refseq_table),len(taxonomy_file),len(filtered_table)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refseq_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refseq_table = read_current_assembly_summary_with_pandas('./assembly_summary_refseq (1).txt',['Complete Genome','Chromosome'])\n",
    "taxonomy_table = read_taxonomy_table('cyanobacteria.taxid')\n",
    "filtered_table = filter_table_by_taxonomy(refseq_table,taxonomy_table)\n",
    "\n",
    "print(\"[+] reduced genome table to: {}\".format(reduction_amount(refseq_table,filtered_table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create taxid file with the get_species_taxids.sh BLAST C++ script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Trying to get species level taxonomic nodes for 2\n",
      "[+] spawned new process: 2616\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    taxid = get_species_taxid('lukas.becker@hhu.de','eubacteria')[0]\n",
    "    print(\"[*] Trying to get species level taxonomic nodes for {}\".format(taxid))\n",
    "    output=open('eubacteria.taxid','w')\n",
    "    pid = subprocess.Popen(['get_species_taxids.sh -t {}'.format(taxid)],stdout=output,shell=True)\n",
    "    print(\"[+] spawned new process: {}\".format(pid.pid))\n",
    "    os.waitpid(pid.pid,0)\n",
    "    output.close()\n",
    "    \n",
    "    #signal = pid.communicate()\n",
    "    #print(\"[*] waiting for get_species_taxids.sh to finish: {}\".format(signal))\n",
    "except Exception as e:\n",
    "    print(\"[-] Exception occured: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from Bio import Entrez\n",
    "\n",
    "def get_species_taxid(user_email,scientific_name):\n",
    "    try:\n",
    "        Entrez.email = user_email\n",
    "        search = Entrez.esearch(term=scientific_name, db=\"taxonomy\", retmode=\"xml\")\n",
    "        record = Entrez.read(search)\n",
    "        taxid = record['IdList'][0]\n",
    "        translation = record['QueryTranslation']\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"[-] There is no taxonomic node defined by your specified scientific name: {} Exception: {}\".format(scientific_name,e))\n",
    "    return taxid, translation\n",
    "\n",
    "def write_species_taxid_file(user_email,scientific_name):\n",
    "    taxid = get_species_taxid(user_email,scientific_name)[0]\n",
    "    try:\n",
    "        taxid = get_species_taxid(user_email,scientific_name)[0]\n",
    "        output_filename = '../taxonomic_nodes/'+scientific_name + '.taxid'\n",
    "        print(\"[*] Trying to get species level taxonomic nodes for {}\".format(taxid))\n",
    "        output=open(output_filename,'w')\n",
    "        pid = subprocess.Popen(['get_species_taxids.sh -t {}'.format(taxid)],stdout=output,shell=True)\n",
    "        print(\"\\t[+] spawned new process: {}\".format(pid.pid))\n",
    "        os.waitpid(pid.pid,0)\n",
    "        output.close()\n",
    "    \n",
    "    #signal = pid.communicate()\n",
    "    #print(\"[*] waiting for get_species_taxids.sh to finish: {}\".format(signal))\n",
    "    except Exception as e:\n",
    "        print(\"[-] Exception occured: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Trying to get species level taxonomic nodes for 34735\n",
      "\t[+] spawned new process: 606\n"
     ]
    }
   ],
   "source": [
    "write_species_taxid_file('lukas.becker@hhu.de','bees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Django transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "database_description = \"Cyanobacteria Complete Genome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'media/databases/refseq_databases/CYANOBACTERIA_COMPLETE_GENOME.database.faa'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_database_file = 'media/' + 'databases/' + 'refseq_databases/' + database_description.replace(' ','_').upper() + '.database.faa'\n",
    "path_to_database_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}